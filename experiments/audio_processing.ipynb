{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get narration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "speech_file_path = os.path.join('audios', \"speech.mp3\")\n",
    "response = client.audio.speech.create(\n",
    "  model=\"tts-1\",\n",
    "  voice=\"alloy\",\n",
    "  input=\"Today is a wonderful day to build something people love!\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio(text, output_file_path=os.path.join('audios', \"speech.mp3\"), voice=\"alloy\", model=\"tts-1\"):  \n",
    "    client = OpenAI()\n",
    "\n",
    "    response = client.audio.speech.create(\n",
    "        model=model,\n",
    "        voice=voice,\n",
    "        input=text\n",
    "    )\n",
    "\n",
    "    response.write_to_file(output_file_path)\n",
    "\n",
    "    return output_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = generate_audio(\"Today is a wonderful day to build something people love!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0, 'seek': 0, 'start': 0.0, 'end': 3.359999895095825, 'text': ' Today is a wonderful day to build something people love.', 'tokens': [50364, 2692, 307, 257, 3715, 786, 281, 1322, 746, 561, 959, 13, 50532], 'temperature': 0.0, 'avg_logprob': -0.3746528923511505, 'compression_ratio': 0.9032257795333862, 'no_speech_prob': 0.0004466415848582983}]\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "audio_file = open(output_path, \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "  file=audio_file,\n",
    "  model=\"whisper-1\",\n",
    "  response_format=\"verbose_json\",\n",
    "  timestamp_granularities=[\"segment\"]   # can do word level granularity as well. See https://platform.openai.com/docs/api-reference/audio/createTranscription#audio-createtranscription-timestamp_granularities\n",
    ")\n",
    "\n",
    "print(transcript.segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
